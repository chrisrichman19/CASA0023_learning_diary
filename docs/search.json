[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Remotely Sensing Learning Diary",
    "section": "",
    "text": "CASA0023: Remotely Sensing Cities and Environments Learning Diary",
    "crumbs": [
      "**CASA0023:** Remotely Sensing Cities and Environments Learning Diary"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Introduction to Remote Sensing",
    "section": "",
    "text": "1.1 Summary\nThis week, we looked at the fundamentals of remote sensing focusing on its technical workings, and applications. The focus was on understanding how electromagnetic energy is used to gather data about the Earth’s surface. The lectures introduced key concepts, including the electromagnetic spectrum, sensor types, and image processing techniques.\nRemote sensing is the science of obtaining information about the Earth’s via sensors. This information is obtained by sensors that observe energy, usually from the sun, reflected or emitted from the earth’s surface (Tempfli et al. 2009). This energy can be modelled as waves, where the shorter the wavelength, the higher the frequency and energy. These sensors measure how different materials reflect or absorb energy at specific wavelengths. Remote sensing operates across bands on the electromagnetic spectrum, including wavelengths visible to the human eye and beyond, like near-infrared radiation. For example, healthy vegetation reflects a lot of near-infrared energy because of its cellular structure, while unhealthy vegetation reflects less (Butcher 2016). By analysing these spectral reflectance curves, scientists can identify spectral signatures for plant health, soil types, or water quality using specialised software such as SNAP and R (which we used in our practical).\nSensors can be passive, relying on naturally reflected sunlight, or active, emitting their own energy (e.g., radar). This capability allows scientists to gather data on vegetation health, land use, and atmospheric conditions (Tempfli et al. 2009).\nReflecting on this introductory week, the power of remote sensing is apparent. Its ability to provide a continuous view of the planet opens up possibilities for environmental monitoring, resource management, and disaster response.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "01_intro.html#application",
    "href": "01_intro.html#application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nIn the practical we looked at data from Landsat 8 and Sentinel-2; two of the most widely used Earth observation missions that provide freely available satellite data. The ready availability of data from these missions has fundamentally changed the landscape of remote sensing research, leading to a huge increase in applications across different fields\nLandsat 8, launched in 2013, offers a spatial resolution of 30 meters and 16-day revisit intervals (“Landsat 8 | u.s. Geological Survey,” n.d.). It captures imagery across nine spectral bands using its sensor (Operational Land Imager). It differs from Sentinel-2 as it captures thermal data at a resolution of 100 meters.\nTherefore, it has become a key data source for studies requiring long-term trend analysis and surface temperature information. For instance, (Kaplan, Avdan, and Avdan 2018) utilised Landsat’s thermal bands to map urban heat islands in Skopje, tracking their expansion over multiple years. Another example is (Fahnestock et al. 2016), with their work on mapping glacier melting rates.\nSentinel-2, launched in 2015 and 2024 as a dual-satellite mission, provides a more frequent revisit time of five days and captures data across 13 spectral bands at spatial resolutions ranging from 10 to 60 meters (ESA, n.d.). The relatively short revisit period makes it ideal for near real-time monitoring of dynamic events such as natural disasters.\n(Jelének and Kopačková-Strnadová 2021), for example, showcased the effectiveness of Sentinel data in automatically detecting damage from earthquakes, providing crucial information for disaster response efforts. As well as the technical aspects of Sentinel data, they highlight its accessibility as a big asset for timely impact assessments (Jelének and Kopačková-Strnadová 2021).\nChaves et al., (2020) also notes how the red-edge bands are particularly good for assessing vegetation health, which enable researchers to detect subtle changes in plant conditions, making it useful for environmental research (Chaves, Picoli, and Sanches 2020).\nBoth Landsat 8 and Sentinel-2 are great for monitoring Earth’s surface, but as mentioned in the paragraphs above, their sensors capture data slightly differently (Mandanici and Bitelli 2016). This means you need to be careful when combining data from the two sensors, taking into consideration the differences in bands and resolution.\nOverall, it is clear that this is an exciting time for remote sensing research - From a European Space Agency report, released at the beginning of 2025 research using ESA earth observation satellites has exploded since 2002 (ESSC 2025). “According to statistics provided by ESA, over 4,000 scientific publications utilising ESA and Sentinel satellites have been published in peer-reviewed journals in 2024 alone” (ESSC 2025, 42)\n\n\n\nEuropean Space Agency (ESSC 2025)\n\n\nWhilst Landsat and Sentinel satellites dominant research due to their availability, there are also plenty of private commercial earth observation missions being launched by commercial companies as shown below.\n\n\n\nEO satellite companies (Aravind 2025)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "01_intro.html#reflection",
    "href": "01_intro.html#reflection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nreflection on lecture material - elcetromagnetic blah blah\nreflection on remote sensing in general\nI am impressed by how much remote sensing data is freely available despite the million of pounds cost of launching satellites and all the research involved. They appear to have democratised remote sensing research, allowing for policy development and R&D in many domains including agriculture and urban planning. It lowers the barrier to entry for researchers globally, allowing for a wide range of institutions and individuals to contribute to the understanding of Earth.\nI also found a very helpful newsletter by TerraWatch Space called Last Week in Observation that releases weekly updates on the commercial and academic world in remote sensing, so I will keep an eye on that for any new research or innovations in the field.\nLooking ahead, the challenge lies in effectively translating remote sensing data into actionable policies. This week has sparked an interest in exploring how these tools and data can be applied to ongoing environmental issues. I expect these skills and this knowledge, or at least something similar, will be highly relevant and valuable in the future.\n\n\n\n\nAravind. 2025. “Last Week in Earth Observation: January 20, 2024.” https://newsletter.terrawatchspace.com/last-week-in-earth-observation-january-20-2024/.\n\n\nButcher, Ginger. 2016. Tour of the Electromagnetic Spectrum. Government Printing Office.\n\n\nChaves, Michel E. D., Michelle C. A. Picoli, and Ieda D. Sanches. 2020. “Recent Applications of Landsat 8/OLI and Sentinel-2/MSI for Land Use and Land Cover Mapping: A Systematic Review.” https://www.mdpi.com/2072-4292/12/18/3062.\n\n\nESA. n.d. “Sentinel-2.” https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2.\n\n\nESSC. 2025. “ESSC ESA Earth Observation Groundbreaking Science Discoveries.” https://esamultimedia.esa.int/docs/EarthObservation/ESSC_ESA_EO_Groundbreaking_Science_Discoveries.pdf?ref=newsletter.terrawatchspace.com.\n\n\nFahnestock, Mark, Ted Scambos, Twila Moon, Alex Gardner, Terry Haran, and Marin Klinger. 2016. “Rapid Large-Area Mapping of Ice Flow Using Landsat 8.” Remote Sensing of Environment, Landsat 8 science results, 185 (November): 84–94. https://doi.org/10.1016/j.rse.2015.11.023.\n\n\nJelének, Jan, and Veronika Kopačková-Strnadová. 2021. “Synergic Use of Sentinel-1 and Sentinel-2 Data for Automatic Detection of Earthquake-Triggered Landscape Changes: A Case Study of the 2016 Kaikoura Earthquake (Mw 7.8), New Zealand.” Remote Sensing of Environment 265 (November): 112634. https://doi.org/10.1016/j.rse.2021.112634.\n\n\nKaplan, Gordana, Ugur Avdan, and Zehra Yigit Avdan. 2018. “Urban Heat Island Analysis Using the Landsat 8 Satellite Data: A Case Study in Skopje, Macedonia.” https://www.mdpi.com/2504-3900/2/7/358.\n\n\n“Landsat 8 | u.s. Geological Survey.” n.d. https://www.usgs.gov/landsat-missions/landsat-8.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary Comparison of Sentinel-2 and Landsat 8 Imagery for a Combined Use.” Remote Sensing 8 (12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nTempfli, K., G. C. Huurneman, W. H. Bakker, L. L. F. Janssen, W. F. Feringa, A. S. M. Gieske, K. A. Grabmaier, et al. 2009. Principles of Remote Sensing: An Introductory Textbook. International Institute for Geo-Information Science; Earth Observation. https://research.utwente.nl/en/publications/principles-of-remote-sensing-an-introductory-textbook-4.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "02_portfolio.html",
    "href": "02_portfolio.html",
    "title": "2  Portfolio and Xaringan Presentation",
    "section": "",
    "text": "2.1 Sentinel-1c",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Portfolio and Xaringan Presentation</span>"
    ]
  },
  {
    "objectID": "02_portfolio.html#reflection",
    "href": "02_portfolio.html#reflection",
    "title": "2  Portfolio and Xaringan Presentation",
    "section": "2.2 Reflection",
    "text": "2.2 Reflection\nXaringan presentations at first appear a lot more complex than comparable programs like PowerPoint and Slides, particularly when it comes to tasks like resizing images and restyling text. I think that it will take a while to master all the syntax before it becomes intuitive.\nI looked into the benefits of Xaringan, which its users claim make it more powerful than traditional presentation software like PowerPoint or Google Slides. For example, the ability to directly include R code and its output into slides is a big professed advantage for its user. However, at this stage, I am not yet convinced and remain unconverted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Portfolio and Xaringan Presentation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "8  References",
    "section": "",
    "text": "References\n\n\nAravind. 2025. “Last Week in Earth Observation: January 20,\n2024.” https://newsletter.terrawatchspace.com/last-week-in-earth-observation-january-20-2024/.\n\n\nButcher, Ginger. 2016. Tour of the Electromagnetic Spectrum.\nGovernment Printing Office.\n\n\nChaves, Michel E. D., Michelle C. A. Picoli, and Ieda D. Sanches. 2020.\n“Recent Applications of Landsat 8/OLI and Sentinel-2/MSI for Land\nUse and Land Cover Mapping: A Systematic Review.” https://www.mdpi.com/2072-4292/12/18/3062.\n\n\nDare, Paul M. 2005. “Shadow Analysis in High-Resolution Satellite\nImagery of Urban Areas.” Photogrammetric Engineering &\nRemote Sensing 71 (2): 169–77. https://doi.org/10.14358/PERS.71.2.169.\n\n\nEarth Science Data Systems, NASA. 2024. “Digital Elevation/Terrain\nModel (DEM) | NASA Earthdata.” https://www.earthdata.nasa.gov/topics/land-surface/digital-elevation-terrain-model-dem.\n\n\nESA. n.d. “Sentinel-2.” https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2.\n\n\nESSC. 2025. “ESSC ESA Earth Observation Groundbreaking Science\nDiscoveries.” https://esamultimedia.esa.int/docs/EarthObservation/ESSC_ESA_EO_Groundbreaking_Science_Discoveries.pdf?ref=newsletter.terrawatchspace.com.\n\n\nFahnestock, Mark, Ted Scambos, Twila Moon, Alex Gardner, Terry Haran,\nand Marin Klinger. 2016. “Rapid Large-Area Mapping of Ice Flow\nUsing Landsat 8.” Remote Sensing of Environment, Landsat\n8 science results, 185 (November): 84–94. https://doi.org/10.1016/j.rse.2015.11.023.\n\n\nGLA. 2021. The London Plan: The Spatial Development Strategy for\nGreater London, March 2021. London: Greater London Authority.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A.\nTyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of\n21st-Century Forest Cover Change.” Science 342 (6160):\n850–53. https://doi.org/10.1126/science.1244693.\n\n\nHaque, M. O., R. Rengarajan, M. Lubke, M. N. Hasan, A. Shrestha, J. L.\nShaw, A. Denevan, et al. 2024. “ECCOE Landsat Quarterly\nCalibration and Validation Report.”\n\n\nHuang, Xin, Liangpei Zhang, and Wei Gong. 2011. “Information\nFusion of Aerial Images and LIDAR Data in Urban Areas: Vector-Stacking,\nRe-Classification and Post-Processing Approaches.”\nInternational Journal of Remote Sensing 32 (1): 69–84. https://doi.org/10.1080/01431160903439882.\n\n\nJelének, Jan, and Veronika Kopačková-Strnadová. 2021. “Synergic\nUse of Sentinel-1 and Sentinel-2 Data for Automatic Detection of\nEarthquake-Triggered Landscape Changes: A Case Study of the 2016\nKaikoura Earthquake (Mw 7.8), New Zealand.” Remote Sensing of\nEnvironment 265 (November): 112634. https://doi.org/10.1016/j.rse.2021.112634.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing.\n4th ed. A Remote Sensing Perspective. Pearson Higher Education US.\n\n\nKaplan, Gordana, Ugur Avdan, and Zehra Yigit Avdan. 2018. “Urban\nHeat Island Analysis Using the Landsat 8 Satellite Data: A Case Study in\nSkopje, Macedonia.” https://www.mdpi.com/2504-3900/2/7/358.\n\n\nKennedy, Robert E., Zhiqiang Yang, and Warren B. Cohen. 2010.\n“Detecting Trends in Forest Disturbance and Recovery Using Yearly\nLandsat Time Series: 1. LandTrendr  Temporal Segmentation\nAlgorithms.” Remote Sensing of Environment 114 (12):\n2897–2910. https://doi.org/10.1016/j.rse.2010.07.008.\n\n\nKennedy, Robert E., Zhiqiang Yang, Noel Gorelick, Justin Braaten, Lucas\nCavalcante, Warren B. Cohen, and Sean Healey. 2018.\n“Implementation of the LandTrendr Algorithm on Google Earth\nEngine.” Remote Sensing 10 (5): 691. https://doi.org/10.3390/rs10050691.\n\n\nLandsat. 2021. “Landsat Collection 1 Vs Collection 2 Summary |\nU.S. Geological Survey.” https://www.usgs.gov/media/files/landsat-collection-1-vs-collection-2-summary.\n\n\n“Landsat 8 | u.s. Geological Survey.” n.d. https://www.usgs.gov/landsat-missions/landsat-8.\n\n\n“Landsat Levels of Processing | U.S. Geological Survey.”\n2017. https://www.usgs.gov/landsat-missions/landsat-levels-processing.\n\n\nLe, Hieu, and Dimitris Samaras. 2020. “From Shadow Segmentation to\nShadow Removal.” In, edited by Andrea Vedaldi, Horst Bischof,\nThomas Brox, and Jan-Michael Frahm, 264–81. Cham: Springer International\nPublishing. https://doi.org/10.1007/978-3-030-58621-8_16.\n\n\nMandanici, Emanuele, and Gabriele Bitelli. 2016. “Preliminary\nComparison of Sentinel-2 and Landsat 8 Imagery for a Combined\nUse.” Remote Sensing 8 (12): 1014. https://doi.org/10.3390/rs8121014.\n\n\nMiliaresis, George, and Nikolaos Kokkas. 2007. “Segmentation and\nObject-Based Classification for the Extraction of the Building Class\nfrom LIDAR DEMs.” Computers & Geosciences 33 (8):\n1076–87. https://doi.org/10.1016/j.cageo.2006.11.012.\n\n\nPradhan, Biswajeet, Ahmed A. Ahmed, Subrata Chakraborty, Abdullah\nAlamri, and Chang-Wook Lee. 2021. “Orthorectification of\nWorldView-3 Satellite Image Using Airborne Laser Scanning Data.”\nJournal of Sensors 2021 (1): 5273549. https://doi.org/10.1155/2021/5273549.\n\n\nQuaranta, Emanuele, Chiara Dorati, and Alberto Pistocchi. 2021.\n“Water, Energy and Climate Benefits of Urban Greening Throughout\nEurope Under Different Climatic Scenarios.” Scientific\nReports 11 (1): 12163. https://doi.org/10.1038/s41598-021-88141-7.\n\n\nRolf, Esther, Konstantin Klemmer, Caleb Robinson, and Hannah Kerner.\nn.d. “Mission Critical – Satellite Data Is a Distinct Modality in\nMachine Learning.” https://doi.org/10.48550/arXiv.2402.01444.\n\n\nRoy, Samapriya, Swetnam T., and Saah A. 2025.\n“Samapriya/Awesome-Gee-Community-Datasets: Community Catalog\n(3.2.0).” https://doi.org/10.5281/zenodo.14757583.\n\n\nSemeraro, Teodoro, Aurelia Scarano, Riccardo Buccolieri, Angelo Santino,\nand Eeva Aarrevaara. 2021. “Planning of Urban Green Spaces: An\nEcological Perspective on Human Benefits.” Land 10 (2):\n105. https://doi.org/10.3390/land10020105.\n\n\nSu, Nan, Ye Zhang, Shu Tian, Yiming Yan, and Xinyuan Miao. 2016.\n“Shadow Detection and Removal for Occluded Object Information\nRecovery in Urban High-Resolution Panchromatic Satellite Images.”\nIEEE Journal of Selected Topics in Applied Earth Observations and\nRemote Sensing 9 (6): 2568–82. https://doi.org/10.1109/JSTARS.2016.2570234.\n\n\nTamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush,\nSarina Adeli, and Brian Brisco. 2020. “Google Earth Engine for\nGeo-Big Data Applications: A Meta-Analysis and Systematic\nReview.” ISPRS Journal of Photogrammetry and Remote\nSensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\nTempfli, K., G. C. Huurneman, W. H. Bakker, L. L. F. Janssen, W. F.\nFeringa, A. S. M. Gieske, K. A. Grabmaier, et al. 2009. Principles\nof Remote Sensing: An Introductory Textbook. International\nInstitute for Geo-Information Science; Earth Observation. https://research.utwente.nl/en/publications/principles-of-remote-sensing-an-introductory-textbook-4.\n\n\nYang, Lei, Guowu Yuan, Hao Zhou, Hongyu Liu, Jian Chen, and Hao Wu. n.d.\n“RS-YOLOX: A High Precision Detector for Object Detection in\nSatellite Remote Sensing Images.” https://doi.org/10.3390/app12178707.\n\n\nZhao, Qiang, Le Yu, Xuecao Li, Dailiang Peng, Yongguang Zhang, and Peng\nGong. 2021. “Progress and Trends in the Application of Google\nEarth and Google Earth Engine.” Remote Sensing 13 (18):\n3778. https://doi.org/10.3390/rs13183778.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "03_corrections.html",
    "href": "03_corrections.html",
    "title": "3  Corrections and Enhancements",
    "section": "",
    "text": "3.1 Summary\nThis week, we explored the steps needed to turn raw satellite imagery into reliable, analysis-ready data.\nI learned that transforming raw remote sensing data into something usable for analysis is far from straightforward, with technical geometric, atmospheric, orthorectification, and radiometric corrections needed.\nModern remote sensing products like Landsat’s Analysis Ready Data (ARD) come pre-corrected. But it important to know what corrections are applied to these products. For example, Landsat offers three processing levels: Level 0 (minor ancillary corrections), Level 1 (radiometrically and geometrically corrected) and Level 2 (atmospherically corrected and terrain-adjusted) (Haque et al. 2024).\nDepending on your needs",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancements</span>"
    ]
  },
  {
    "objectID": "03_corrections.html#application",
    "href": "03_corrections.html#application",
    "title": "3  Corrections and Enhancements",
    "section": "3.2 Application",
    "text": "3.2 Application\nRemote Sensing Challenges and Corrections in Urban Environments\nI decided to focus on the distinct issues with remote sensing in urban areas, as I found that researchers often highlight challenges with collecting data in dense cities, so they often have to get creative with their solutions.\nAnd with satellite imagery being increasingly used in urban settings for detecting land use change, transport planning, environmental monitoring, it is important that these images accurately reflect the real environment (Pradhan et al. 2021).\nUrban areas often exhibit high intra-class variability, which means that similar materials appear spectrally different, due to shadows, reflective surfaces and high-rise buildings, making classification challenging (Huang, Zhang, and Gong 2011).\nSome studies attempt to address this by fusing multi-angle satellite data (e.g., combining Landsat with Sentinel-2) or combining LiDAR data to create more accurate elevation models for cities. (Huang, Zhang, and Gong 2011; Miliaresis and Kokkas 2007).\n(Huang, Zhang, and Gong 2011) found that the height features obtained from LiDAR data significantly improved urban land-cover classification.\nUrban areas also introduce shadowing effects, where buildings cast shadows that obscure features on the ground, making it difficult to classify land cover accurately (Dare 2005; Le and Samaras 2020). Researchers have addressed this by applying shadow detection and removal algorithms that estimate surface reflectance in obscured areas (Su et al. 2016).\nOther challenges\n\nAdjacency Effect: Reflective surfaces (e.g., glass facades) scatter light into neighbouring pixels, skewing surface reflectance values.\nThermal Anomalies: Concrete and metal structures absorb/re-radiate heat differently than natural terrain, distorting temperature measurements. Particularly impactful for urban heat island research.\n\nYet gaps remain. Most of these urban corrections don’t have out-of-the-box solution as they are computationally intensive and require localised datasets (e.g., LiDAR), perhaps limiting their real-time applications and scalability.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancements</span>"
    ]
  },
  {
    "objectID": "03_corrections.html#reflection",
    "href": "03_corrections.html#reflection",
    "title": "3  Corrections and Enhancements",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThis week showed that image correction is a balance between precision and practicality. Methods like DOS or PIFs make corrections more accessible, but, because they rely on assumptions – like the idea that the darkest pixel is just atmospheric noise, or that some surfaces always reflect light the same way – they have limits.\nFor example, in urban areas, where spectral variability is already high, these simplifications might not be suitable for detailed analysis\nThe additional LiDAR, 3D city models, and combination of images from different times, as discussed in the Applications section, show that for cities, you often need more accuracy and context then out-of-the-box corrections.\nThe availability of ready-to-use data is great because it saves time and effort, but also made me question the assumptions behind vendor-applied corrections. What trade-offs are hidden in these standardised products? Can we always trust them without understanding their limitations? How does it affect comparison of products? Is there a risk that users might become detached from understanding the processing, which may not be generalisable to every scenario.\nThis week’s work has made it clear that while pre-processed data is convenient, really understanding image correction and its details, especially for cities, is still essential for doing good and useful remote sensing work\n\n\n\n\nDare, Paul M. 2005. “Shadow Analysis in High-Resolution Satellite Imagery of Urban Areas.” Photogrammetric Engineering & Remote Sensing 71 (2): 169–77. https://doi.org/10.14358/PERS.71.2.169.\n\n\nEarth Science Data Systems, NASA. 2024. “Digital Elevation/Terrain Model (DEM) | NASA Earthdata.” https://www.earthdata.nasa.gov/topics/land-surface/digital-elevation-terrain-model-dem.\n\n\nHaque, M. O., R. Rengarajan, M. Lubke, M. N. Hasan, A. Shrestha, J. L. Shaw, A. Denevan, et al. 2024. “ECCOE Landsat Quarterly Calibration and Validation Report.”\n\n\nHuang, Xin, Liangpei Zhang, and Wei Gong. 2011. “Information Fusion of Aerial Images and LIDAR Data in Urban Areas: Vector-Stacking, Re-Classification and Post-Processing Approaches.” International Journal of Remote Sensing 32 (1): 69–84. https://doi.org/10.1080/01431160903439882.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing. 4th ed. A Remote Sensing Perspective. Pearson Higher Education US.\n\n\nLandsat. 2021. “Landsat Collection 1 Vs Collection 2 Summary | U.S. Geological Survey.” https://www.usgs.gov/media/files/landsat-collection-1-vs-collection-2-summary.\n\n\n“Landsat Levels of Processing | U.S. Geological Survey.” 2017. https://www.usgs.gov/landsat-missions/landsat-levels-processing.\n\n\nLe, Hieu, and Dimitris Samaras. 2020. “From Shadow Segmentation to Shadow Removal.” In, edited by Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, 264–81. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-58621-8_16.\n\n\nMiliaresis, George, and Nikolaos Kokkas. 2007. “Segmentation and Object-Based Classification for the Extraction of the Building Class from LIDAR DEMs.” Computers & Geosciences 33 (8): 1076–87. https://doi.org/10.1016/j.cageo.2006.11.012.\n\n\nPradhan, Biswajeet, Ahmed A. Ahmed, Subrata Chakraborty, Abdullah Alamri, and Chang-Wook Lee. 2021. “Orthorectification of WorldView-3 Satellite Image Using Airborne Laser Scanning Data.” Journal of Sensors 2021 (1): 5273549. https://doi.org/10.1155/2021/5273549.\n\n\nSu, Nan, Ye Zhang, Shu Tian, Yiming Yan, and Xinyuan Miao. 2016. “Shadow Detection and Removal for Occluded Object Information Recovery in Urban High-Resolution Panchromatic Satellite Images.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 9 (6): 2568–82. https://doi.org/10.1109/JSTARS.2016.2570234.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancements</span>"
    ]
  },
  {
    "objectID": "03_corrections.html#summary",
    "href": "03_corrections.html#summary",
    "title": "3  Corrections and Enhancements",
    "section": "",
    "text": "level 0 and 1 for if you want control over atmospheric corrections\nlevel 2 - analysis ready - using NASA’s ready made algorithms.\n\n\n3.1.0.1 Corrections:\nGeometric correction\nSince satellites capture images from shifting orbits and angles, distortions can occur. This is often corrected by using Ground Control Points (GCPs) (Jensen 2015). Ground control points are location on the Earth’s surface that can be accurately located and act as reference points (Jensen 2015). Algorithms match these GCPs in the captured image, which guide the transformations needed on the raw image to fix any distortions.\nBoth Landsat level 1 and 2 products match pixels from raw images to Earth’s coordinates using ground control points(Landsat 2021).\nHowever, the accuracy of this correction is not absolute; cloud cover, snow, or ice can obscure GCP visibility, which can limit its effectiveness in certain environments (“Landsat Levels of Processing | U.S. Geological Survey” 2017).\nAtmospheric correction:\nLight interacts with the atmosphere before reaching a sensor so particles like dust, water vapor, and pollutants scatter and absorb light, affecting the captured image quality.\nDark Object Subtraction (DOS) is a common fix, which assumes that the darkest pixel represents atmospheric noise so that value is subtracted from every pixel (Jensen 2015). Another method is using stable surfaces, like roads or rooftops, that maintain consistent reflectance over time. These are called Pseudo-invariant features (PIFs). By assuming that these features do not change between images, researchers use them to adjust images (Jensen 2015).\nThese methods are refered to as relative atmospheric correction and is often used as an estimate in the absence of synchronised surface-reflectance data(Jensen 2015).\nIn contrast, absolute atmospheric correction, exemplified by Landsat Level 2, uses external atmospheric data. Landsat uses aerosol and water vapor data from MODIS to adjust its image, rather than relying on assumptions used in relative methods (Landsat 2021).\nOrthorectification correction\nElevation distortions in imagery are corrected using Digital Elevation Models (DEMs) in a process called orthorectification, which ensures images appear as if viewed from directly above, removing terrain-induced geometric inaccuracies.\nHowever, tall buildings and bridges introduce their own artifacts, which are harder to correct as they are not included in standard DEMs (Earth Science Data Systems 2024).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancements</span>"
    ]
  },
  {
    "objectID": "04_policy.html",
    "href": "04_policy.html",
    "title": "4  Policy",
    "section": "",
    "text": "4.1 Summary\nThe London Plan’s Policy G5 focuses on urban greening as a fundamental element of site and building design for major developments (GLA 2021). This policy encourages integrating high-quality landscaping, green roofs, green walls, and sustainable drainage solutions to enhance biodiversity and mitigate the urban heat island effect. The UGF assigns scores from 0 (impermeable surfaces) to 1 (semi-natural vegetation) to quantify greening efforts (GLA 2021). This index attempts to ensure that new developments contribute towards London’s environmental goals.\nFigure Source:The London Plan, 2021 (GLA 2021, 324)\nThe practical benefits underpinning this Urban greening policy is clear as there is significant evidence that greening improves air quality, increases biodiversity, and improves climate resilience (Semeraro et al. 2021; Quaranta, Dorati, and Pistocchi 2021). However, there are questions to consider regarding the practical effectiveness and implementation of UGF.\nHow will meaningful ecological outcomes in the real-world be prioritised over checklist-compliance ?\nHow can spatial disparities and local needs be addressed ?\nWhat barriers exist in its implementation? And how will greening maintenance be assessed after the planning application has been approved?\nThese are all important questions that a holistic solution for a healthier urban spaces need to address.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "04_policy.html#application",
    "href": "04_policy.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nRemotely sensed data could directly support the goals of Policy G5 in assessing and monitoring urban greening efforts. Satellite imagery and LiDAR could be used to quantify vegetation cover and track changes over time. One example researchers could implement is Normalized Difference Vegetation Index (NDVI) analysis, a technique used to assess vegetation health by measuring the difference between near-infrared (which vegetation strongly reflects) and red light (which vegetation absorbs). This index could be used to identify plant cover in neighbourhoods, monitor changes over time, and assess how well urban-greening contribute to reducing the urban heat island effect.\nRemote sensing data could aid a more proactive approach, by identifying disparities in urban greening across different boroughs, and supporting a more equitable implementation of the policy. This approach allows for the prioritisation of interventions in neighbourhoods lacking greening or experiencing issues such as poor air quality or urban heat island impacts. By recognising the importance of local conditions, remote sensing tools can be used to help tailor greening requirements to meet specific areas needs, acknowledging that developments in areas like Richmond may have different needs compared to those in the City.\nRemote sensing would offer a practical solution to go beyond checklist compliance and instead focus in on the real-world environmental outcomes of urban greening. Additionally it provides ongoing monitoring and support the maintenance of greenery post-development approval, as well as inform necessary adaptations in response to changing circumstances, such as those driven by global warming in the future.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "04_policy.html#reflection",
    "href": "04_policy.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThis exercise has highlighted the intersection between remote sensing and urban policy, emphasising how remote sensing data can enhance the effectiveness of greening initiatives. While satellite and aerial data offer powerful monitoring tools, challenges such as data resolution, cloud cover, and accessibility constraints may limit real-world application. Integrating EO into policy decisions requires collaboration between urban planners, environmental scientists, and data analysts. Personally, I found the application of NDVI particularly insightful, as it demonstrates a tangible way to assess vegetation health and policy compliance.\nThis exercise highlighted the potential of remote sensing to bridge policy goals and on-ground implementation. While remote sensing offers a powerful solution for monitoring urban greening, practical barriers like data resolution, cost, and technical capacity could potentially limit its universal adoption, raising equity concerns, where cash-strapped councils could struggle to adopt remote sensing tools, risking uneven policy enforcement.\n\n\n\n\nGLA. 2021. The London Plan: The Spatial Development Strategy for Greater London, March 2021. London: Greater London Authority.\n\n\nQuaranta, Emanuele, Chiara Dorati, and Alberto Pistocchi. 2021. “Water, Energy and Climate Benefits of Urban Greening Throughout Europe Under Different Climatic Scenarios.” Scientific Reports 11 (1): 12163. https://doi.org/10.1038/s41598-021-88141-7.\n\n\nSemeraro, Teodoro, Aurelia Scarano, Riccardo Buccolieri, Angelo Santino, and Eeva Aarrevaara. 2021. “Planning of Urban Green Spaces: An Ecological Perspective on Human Benefits.” Land 10 (2): 105. https://doi.org/10.3390/land10020105.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "06_classification.html",
    "href": "06_classification.html",
    "title": "6  Classification I",
    "section": "",
    "text": "6.1 Summary\nThis week we learned about image classification, a process that uses machine learning algorithms to categorises pixels, and explored how that can be used in remote sensing, such as for land-use mapping. I’m taking the data science module, so it was interesting to see familiar methods, including classification and regression trees, applied to challenges in remote-sensing. We looked at both supervised and unsupervised methods; supervised learning involves training a model on pre-labeled data to recognise patterns, while unsupervised methods identify clusters within the data, which are then labeled.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "06_classification.html#application",
    "href": "06_classification.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nA popular phenomena in remote sensing research is land use and land cover mapping (Avcı et al. 2023). Classification methods involves categorising each pixel into classes based on its spectral characteristics (Maulik and Chakraborty 2017).\nTeluguntla et al., (2018) used a random forest to precisely classify cropland in Australia and China (Teluguntla et al. 2018).\nExisting global and regional cropland products were derived from medium to coarse resolution (250-m to 1-km) remote sensing data. They needed highly accurate 30-m cropland data as precise cropland maps are crucial for understanding and managing resources related to food and water.\nThe random forest (RF) model was trained using an iterative approach involving a large collection of reference data. To label their data - Ground data was collected in field visits. Over 628 samples were collected in Australia (Teluguntla et al. 2018). Additionally Sub-meter to 5-m Very High Resolution Imagery (VHRI), available for the entire study region, was used to generate cropland versus non-cropland interpretations by multiple analysts across China and Australia, resulting in approximately 1490 data samples. This demonstrates how the process of ‘supervising’ / labeling data for machine learning can be as intense as the analysis itself.\n\n[Teluguntla et al. (2018); p. 338]\nThis intensive supervised learning approach is not uncommon, as existing pre-labelled data is sparse especially in remote sensing (Xu, Zhao, and Wu 2023).\nThe quantity and quality of training data significantly impact classifier performance so extensive field work may be required to correctly label data.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "06_classification.html#reflection",
    "href": "06_classification.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis week highlighted remote sensing’s rapid development and its technical challenges. Tools like deep learning offer transformative capabilities, but, their integration into policy faces hurdles, particularly regarding data quality, computational costs, and model transparency. For instance, extensive fieldwork for training data labelling is resource-intensive, which could complicate policy applications.\nIn a similar vain, in the literature, I found a debate between the need for domain-specific models and utilising repurposed computer vision libraries given computational resources required for training (Rolf et al., n.d.; Lahrichi et al., n.d.). (Rolf et al., n.d.) suggests that satellite data’s temporal, spatial, and spectral complexity, require tailored solutions rather than repurposed computer vision libraries. However, (Lahrichi et al., n.d.) argues that the costs may outweigh the benefits. This debate emphasises balancing innovation with practicality and shows that this field is still in its infancy.\nAnother concern is “black-box” algorithms risk eroding trust in critical applications like disaster monitoring. Explainability must remain at the forefront of remote sensing, ensuring stakeholders understand critical model decisions.\n\n\n\n\nAvcı, Cengiz, Muhammed Budak, Nur Yağmur, and Filiz Balçık. 2023. “Comparison Between Random Forest and Support Vector Machine Algorithms for LULC Classification.” International Journal of Engineering and Geosciences 8 (1): 1–10. https://doi.org/10.26833/ijeg.987605.\n\n\nLahrichi, Saad, Zion Sheng, Shufan Xia, Kyle Bradbury, and Jordan Malof. n.d. “Is Self-Supervised Pre-Training on Satellite Imagery Better Than ImageNet? A Systematic Study with Sentinel-2.” https://doi.org/10.48550/arXiv.2502.10669.\n\n\nMaulik, Ujjwal, and Debasis Chakraborty. 2017. “Remote Sensing Image Classification: A Survey of Support-Vector-Machine-Based Advanced Techniques.” IEEE Geoscience and Remote Sensing Magazine 5 (1): 33–52. https://doi.org/10.1109/MGRS.2016.2641240.\n\n\nRolf, Esther, Konstantin Klemmer, Caleb Robinson, and Hannah Kerner. n.d. “Mission Critical – Satellite Data Is a Distinct Modality in Machine Learning.” https://doi.org/10.48550/arXiv.2402.01444.\n\n\nTeluguntla, Pardhasaradhi, Prasad S Thenkabail, Adam Oliphant, Jun Xiong, Murali Krishna Gumma, Russell G. Congalton, Kamini Yadav, and Alfredo Huete. 2018. “A 30-m Landsat-Derived Cropland Extent Product of Australia and China Using Random Forest Machine Learning Algorithm on Google Earth Engine Cloud Computing Platform.” ISPRS Journal of Photogrammetry and Remote Sensing 144 (October): 325–40. https://doi.org/10.1016/j.isprsjprs.2018.07.017.\n\n\nXu, Tao, Zhicheng Zhao, and Jun Wu. 2023. “Breaking the ImageNet Pretraining Paradigm: A General Framework for Training Using Only Remote Sensing Scene Images.” Applied Sciences 13 (20): 11374. https://doi.org/10.3390/app132011374.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "05_GEE.html",
    "href": "05_GEE.html",
    "title": "5  Google Earth Engine",
    "section": "",
    "text": "5.1 Summary\nThis week’s session introduced Google Earth Engine (GEE), a cloud-based geospatial data platform that aims to simplify the huge technical processes often involved with satellite data.\nA key feature of GEE is its pre-built code libraries for common preprocessing tasks, such as those covered in week three, and a comprehensive data catalog providing direct access to datasets like Landsat and Sentinel, as well as climate, land cover, and building data. This simplifies the coding process and technical aspects, fortunately meaning that I did not have to learn a whole new language from scratch (JavaScript). Another significant advantage of Google Earth Engine is its cloud-based processing environment, which enables computationally intensive tasks to be performed more efficiently than on your own machine. There is also a thriving open-source community in Google Earth Engine so if you have an issue, it is likely that someone else has had it before and solved it:\nhttps://gee-community-catalog.org/ (Roy, T., and A. 2025)\nhttps://github.com/gee-community\nContinuing on from last week, I wanted to use this week’s practical to see how remote sensing could be used to guide policy. So in google earth engine I calculated and visualised NDVI for each borough. Could Google earth engine be used to guide where more urban greening needs to occur? I have included the code and a flowchart below:\nhttps://code.earthengine.google.com/f5cb5c8ca991caa1223ae325a4c66763\nThis quick analysis provides a possible use case for monitoring urban greening as well as a justification for geographically aware policy. This could clearly be further refined, for example, to a finer scale to identify particular neighbourhoods that require more urban greening, but it demonstrates how GEE can be an effective platform for communicating results and reproducible research.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "05_GEE.html#application",
    "href": "05_GEE.html#application",
    "title": "5  Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nIn a paper discussing the trajectory of GEE in research, Zhao et al., (2021) notes how since 2015, applications of GEE expanded, covering fields such as climate studies, agriculture, water resource management, land cover analysis, disaster response, and urban development (Zhao et al. 2021; Tamiminia et al. 2020). And in 2020, almost 300 research papers utilised GEE, demonstrating its growing influence.\nA key strength of GEE lies in its contributions to visualisation and reproducibility. The platform enables researchers to create apps to present datasets interactively, improving researchers ability to communicate their results and make them more accessible to both expert and non-expert audiences. Hansen’s (2013) research paper on global forest change, was accompanied with an interactive GEE visualtion allowing users to explore deforestation patterns themselves (Hansen et al. 2013).\n\nhttps://alexchunet.users.earthengine.app/view/forestchange2020\nAnother example is LandTrendr; a Landsat-based detection algorithm for trends in disturbance and recovery, widely used for the analysis of change in Landsat spectral time series data (Kennedy et al. 2018).\nIt was initially implemented in a proprietary programming language (IDL) with high computational demands however it was transitioned to GEE removing accessibility barriers.\nIt has been used extensively in research, with the original paper “Detecting trends in forest disturbance and recovery using yearly Landsat time series” being cited 1887 times, perfectly demonstrating how GEE can allow advanced algorithms to become more accessible (Kennedy, Yang, and Cohen 2010). The free availability of LandTrendr enables researchers to apply it to study areas without needing extensive the computational infrastructure.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "05_GEE.html#reflection",
    "href": "05_GEE.html#reflection",
    "title": "5  Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nOf all the remote sensing tools I have used so far, I think Google Earth Engine finds the best balance between accessibility and powerful coding. The pre-written code that can be adapted to fit specific needs, making it an ideal tool for both beginners and experienced users.\nThe mini-project I completed on urban greening in London demonstrated just how efficient GEE can be. By adapting existing code from the practicals and utilising its built-in libraries, I was able to complete this analysis in a relatively short amount of time. This is reflected in GEE’s recent explosion in research applications.\nI also found it rewarding to apply these skills to a real-world topic that is both relevant and local to me. Seeing how remote sensing and GEE can be used in a policy setting reinforced its practical applications beyond just academic exercises. While there are limitations, such as data availability and the learning curve for more advanced scripting, the accessibility of GEE makes it a highly attractive tool for integrating Earth Observation data into policy and decision-making.\n\n\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nKennedy, Robert E., Zhiqiang Yang, and Warren B. Cohen. 2010. “Detecting Trends in Forest Disturbance and Recovery Using Yearly Landsat Time Series: 1. LandTrendr  Temporal Segmentation Algorithms.” Remote Sensing of Environment 114 (12): 2897–2910. https://doi.org/10.1016/j.rse.2010.07.008.\n\n\nKennedy, Robert E., Zhiqiang Yang, Noel Gorelick, Justin Braaten, Lucas Cavalcante, Warren B. Cohen, and Sean Healey. 2018. “Implementation of the LandTrendr Algorithm on Google Earth Engine.” Remote Sensing 10 (5): 691. https://doi.org/10.3390/rs10050691.\n\n\nRoy, Samapriya, Swetnam T., and Saah A. 2025. “Samapriya/Awesome-Gee-Community-Datasets: Community Catalog (3.2.0).” https://doi.org/10.5281/zenodo.14757583.\n\n\nTamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush, Sarina Adeli, and Brian Brisco. 2020. “Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis and Systematic Review.” ISPRS Journal of Photogrammetry and Remote Sensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\nZhao, Qiang, Le Yu, Xuecao Li, Dailiang Peng, Yongguang Zhang, and Peng Gong. 2021. “Progress and Trends in the Application of Google Earth and Google Earth Engine.” Remote Sensing 13 (18): 3778. https://doi.org/10.3390/rs13183778.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "06_classification.html#summary",
    "href": "06_classification.html#summary",
    "title": "6  Classification I",
    "section": "",
    "text": "6.1.0.1 Supervised Machine Learning\nWe explored Classification and Regression Trees (CART) and Random Forests. CART creates a decision tree by iteratively partitioning the data based on feature values, aiming to create homogeneous groups within each partition. Random Forests builds on this by using multiple decision trees on random subsets of the data and averaging their predictions. Both methods are good at capturing complex, non-linear relationships between the spectral data and land cover classes.\nAnother supervised method we looked at was Support Vector Machines (SVMs). SVMs work by finding the optimal hyperplane that separates different classes in the data. They aim to maximize the margin between the hyperplane and the closest data points (support vectors). This method is particularly useful when dealing with complex spectral data, as SVMs can effectively handle the high-dimensional datasets common in satellite imagery (Maulik and Chakraborty 2017). All of these supervised methods require labeled training data, where pixels are already associated with known land cover types, to learn the patterns and build the classification model.\nUnsupervised Machine Learning\nUnsupervised classification is employed when we lack prior knowledge about the specific land cover classes present in an image. Essentially, the algorithm is tasked with finding patterns within the data itself. It operates by grouping pixels based on their spectral similarities, without relying on any pre-labeled training data.\nWe looked at two different unsupervised methods; ISODATA, which iteratively refines clusters based on spectral distance, and DBSCAN, which identifies clusters based on pixel density, and effectively handles irregular shapes and noise.\nSo which method to choose?\nThere is no perfect algorithm that is best for every scenario. The best algorithm is case-specfic and depends on the quality and quantity of training data as well as the desired balance between model complexity and interpretability. It may also be useful to experiment with multiple classifiers to assess what fits your data the best in practice. We will look more into this next week when we learn about accuracy measures.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "07_classification-ii.html",
    "href": "07_classification-ii.html",
    "title": "7  Classification II",
    "section": "",
    "text": "7.1 Summary\nThis week, we explored accuracy measures for classification and will use practical applications of SVM and random forest models to explain different accuracy metrics.\nIn last week’s practical, I focused on Bristol, my undergraduate city. I built a simple random forest model using a limited training dataset (3-5 polygons per land type), which included categories such as forest, low urban, high urban, water, and bare earth. For this week, I found SVM code on Google Earth Engine and adapted it for my analysis to compare the accuracy measures across each method.\nRandom Forest Classifier:\nSupport Vector Machine (SVM):\nLight pink: Low urban\nBlue: Water\nDark pink: High urban\nBeige: Grass\nGrey: Bare earth\nGreen: Forest\nVisually, SVM predicts that there is a lot more forest in what the RF predicts as low urban. But how can we interpret these results? There are various measures each with their own advantages and disadvantages.\nAccuracy Assessment\nEach predicted value is placed into this Confusion Matrix, which acts as the foundation for the upcoming measures.\nOverall accuracy measures the total correct prediction in proportion to all prediction\n\\[\n  \\frac{\\text{Number of Correct Predictions}}{\\text{Total Predictions}} = \\frac{TP + TN}{TP + FP + FN + TN}\n  \\]\nRF’s high overall accuracy suggests strong general performance across all classes. SVM’s lower score may stem from misclassifications, especially in overlapping classes",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification II</span>"
    ]
  },
  {
    "objectID": "07_classification-ii.html#application",
    "href": "07_classification-ii.html#application",
    "title": "7  Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nWhilst traditional machine learning techniques like Support Vector Machines and Random Forests are powerful, there are some more complicated classification use-case in remote sensing where more advanced tools are required (Song et al. 2019).\nOne example is object detection which involves identifying the locations and types of specific targets within an image and labeling them with bounding boxes. The use of Convolutional Neural Networks has revolutionised how objects are detected and classified in satellite imagery (Yang et al., n.d.).\nEarly remote sensing workflows relied heavily on manual feature engineering, where texture and spectral signatures were used to distinguish targets like ships or landslides from their surroundings. However, as noted by (Yang et al., n.d.), these methods struggled with the “rich, diverse, and detailed” nature of remote sensing imagery, particularly for small or irregularly shaped objects. For instance, in ship detection, spectral thresholds often failed to differentiate ships from wave patterns or coastal clutter, leading to high false-positive rates (Wu et al. 2018).\nWu et al. (2018) demonstrate how CNNs overcome these shortcomings in their study (Wu et al. 2018).\n\nA CNN indentifies ship heads and estimates their orientation, bypassing background noise, leveraging CNNs’ ability to learn structural patterns automatically.\nA second CNN then uses the ship head’s orientation to propose regions for the full ship. It then distinguishes true ships from false positives (e.g., buildings, wave crests) by analysing relationships between the ship head and surrounding pixels.\nUnlike SVM or Random forest models, Wu et al.’s CNNs autonomously learns features, eliminating the need for manual feature engineering.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification II</span>"
    ]
  },
  {
    "objectID": "07_classification-ii.html#reflection",
    "href": "07_classification-ii.html#reflection",
    "title": "7  Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nIn land classification, traditional cross-validation (e.g., k-fold) risks overestimating model accuracy in spatially autocorrelated data, as nearby training and test samples may share patterns (e.g., within the same land parcel), inflating performance. Spatial cross-validation (CV) addresses this by partitioning data into geographically disjoint folds, ensuring that training and test sets are spatially independent.\nReflection on Model Selection:\nConvolutional Neural Networks (CNNs) are generally more accurate for complex tasks like object detection but they demand substantial labeled data and computational resources. Random Forests (RF) and Support Vector Machines (SVM) are more efficient and interpretable, but struggle with complex spatial patterns.\n\n\n\n\nSong, Jia, Gao ,Shaohua, Zhu ,Yunqiang, and Chenyan and Ma. 2019. “A Survey of Remote Sensing Image Classification Based on CNNs.” Big Earth Data 3 (3): 232–54. https://doi.org/10.1080/20964471.2019.1657720.\n\n\nWu, Fei, Zhiqiang Zhou, Bo Wang, and Jinlei Ma. 2018. “Inshore Ship Detection Based on Convolutional Neural Network in Optical Satellite Images.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 11 (11): 4005–15. https://doi.org/10.1109/JSTARS.2018.2873190.\n\n\nYang, Lei, Guowu Yuan, Hao Zhou, Hongyu Liu, Jian Chen, and Hao Wu. n.d. “RS-YOLOX: A High Precision Detector for Object Detection in Satellite Remote Sensing Images.” https://doi.org/10.3390/app12178707.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification II</span>"
    ]
  },
  {
    "objectID": "05_GEE.html#summary",
    "href": "05_GEE.html#summary",
    "title": "5  Google Earth Engine",
    "section": "",
    "text": "[Load Borough Boundaries] --&gt; [Load Sentinel-2 Data] --&gt; [Filter Data by Date & Bounds] --&gt; [Calculate Mean Image] --&gt; [Calculate NDVI] --&gt; [Visualise NDVI] --&gt; [Print Mean NDVI for Borough] \n\n\n\nMost green boroughs by mean NDVI\n\n\nBorough\nmean NDVI\n\n\n\n\nBromley\n0.540\n\n\nCroydon\n0.510\n\n\nRichmond upon Thames\n0.504\n\n\n\n\nLeast green boroughs by mean NDVI\n\n\nBorough\nmean NDVI\n\n\n\n\nCity of London\n0.127\n\n\nTower Hamlets\n0.274\n\n\nWestminster\n0.302",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "07_classification-ii.html#summary",
    "href": "07_classification-ii.html#summary",
    "title": "7  Classification II",
    "section": "",
    "text": "RF: 0.981 | SVM: 0.879\n\n\n\n7.1.0.1 Class-Specific Metrics (Low Urban Class)\nProducer accuracy measures the true positive rate in a class or the proportion of correctly identified positives relative to actual positives. I will just look at low urban class, so the number of pixels correctly identified pixels as low urban divided by the total pixels in the low urban class.\n\\[\n  \\text{Producer Accuracy} = \\frac{TP}{TP + FN}\n  \\] RF: 0.943 | SVM: 0.478\nSVM misses ~52% of true low urban pixels (e.g., misclassifying them as forest). RF captures ~94% of actual low urban areas.\nUser accuracy measures the proportion of correctly predicted positives relative to all predicted positives.\n\\[\n  \\text{User Accuracy} = \\frac{TP}{TP + FP}\n  \\]\nAgain, using the low urban class - the number of pixels correctly identified as low urban divided by the total number of pixels that are claimed to be low urban.\nRF: 0.955 | SVM: 0.962\nSVM’s and RF’s high User Accuracy means its low urban predictions are reliable here (few false positives).\nThere is also F1 score which is the harmonic mean of precision (UA) and recall (PA). Useful for balancing UA and PA, especially in imbalanced datasets like our own.\nRF: 0.949 | SVM: 0.639\n\n\n7.1.0.2 Additional Metrics\nKappa coefficient is designed to express the accuracy of an image compared to the results done by chance. Ranges from 0 to 1. calls to abandon it as it may not be that useful\n\\[\n  \\kappa = \\frac{\\text{Overall Accuracy} - \\text{Expected Accuracy}}{1 - \\text{Expected Accuracy}}\n  \\]\nWhere expected accuracy =\n\\[\n(\\frac{\\sum (\\text{Row Total} \\times \\text{Column Total})}{N^2})\n\\]\nRF: 0.977 | SVM: 0.855\nBoth models perform better than random chance, but Kappa is debated due to sensitivity to class distribution.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification II</span>"
    ]
  },
  {
    "objectID": "08_SAR_in_GEE.html",
    "href": "08_SAR_in_GEE.html",
    "title": "8  SAR in GEE",
    "section": "",
    "text": "8.1 Summary\nThis week we learned about SAR sensors and imagery which I had looked at before as in week 2, for my presentation, I researched the Sentinel-1 mission which uses this technology.\nSynthetic Aperture Radar (SAR) is an active remote sensing technology that emits its own energy to image the Earth’s surface, unlike passive sensors that rely on sunlight. The microwave signals used by SAR can penetrate through clouds, fog, smoke, and even rain, overcoming a significant limitation of optical sensors.\nSAR imaging involves synthesising a large antenna from the sensor’s motion, capturing both amplitude and phase data. Amplitude reflects the strength of the reflected signal, while the phase provides timing information.\nDifferent polarisations of SAR signals help identify various surface characteristics, and data can be analysed using power, amplitude, or decibel scales. However, SAR images are often affected by speckle noise, which can be reduced by averaging multiple images together.\nInterferometric techniques like InSAR and DInSAR use phase differences to map topography and detect ground movement. By comparing the phase differences between these images, InSAR can generate highly accurate maps of surface topography and detect subtle ground movements.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>SAR in GEE</span>"
    ]
  },
  {
    "objectID": "08_SAR_in_GEE.html#application",
    "href": "08_SAR_in_GEE.html#application",
    "title": "8  SAR in GEE",
    "section": "8.2 Application",
    "text": "8.2 Application\nSAR are particulary useful for identifying change as InSAR can detect millimeter-scale changes in elevation by comparing the phase difference between two or more radar images taken at different times. This makes it ideal for monitoring subsidence, landslides, earthquakes, and infrastructure stability.\nFor example, this paper uses InSAR data, collected between 2015 and 2023, to provide detailed local estimates of verticle land motion (VLM) in California, a significant indicator for sea-level rise (Govorcin et al. 2025).\nCurrent ways of predicting sea level rise often underestimate how much the land is moving because they rely on limited regional data, such as from spatially sparse tide gauges. The Authors found that InSar’s high spatial resolution and coverage was more effective in identifying of local VLM along the coastline compared to traditional methods.\n\nSource: NASA\nBy providing a clearer and more detailed picture of the risks associated with sea-level rise at a local level, this information can help governments develop better-informed policies related to mitigation planning and land-use regulations in coastal zones.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>SAR in GEE</span>"
    ]
  },
  {
    "objectID": "08_SAR_in_GEE.html#reflection",
    "href": "08_SAR_in_GEE.html#reflection",
    "title": "8  SAR in GEE",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nOne of the most interesting aspects of SAR technology is its ability to “see” through various atmospheric and surface obstacles. This opens up a wide range of possibilities for continuous monitoring and rapid response in situations where traditional optical methods are ineffective.\nDespite the numerous advantages of SAR technology, there are also challenges.\nOne significant challenge is the complexity with processing SAR data. Raw SAR data requires specialised tools and expertise for interpretation. The preprocessing steps involved, such as radiometric calibration, de-bursting, multilooking, speckle filtering, and terrain correction, can be technically demanding and time-consuming (Liu, 2022). This means that government agencies would have to develop specialised knowledge in remote sensing and radar ,which can pose a barrier to widespread adoption, particularly for agencies with limited resources or technical expertise.\n\n\n\n\nGovorcin, Marin, David P. S. Bekaert, Benjamin D. Hamlington, Simran S. Sangha, and William Sweet. 2025. “Variable Vertical Land Motion and Its Impacts on Sea Level Rise Projections.” Science Advances 11 (5): eads8163. https://doi.org/10.1126/sciadv.ads8163.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>SAR in GEE</span>"
    ]
  }
]