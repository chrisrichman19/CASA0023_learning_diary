# Classification I

## Summary

This week we learned about image classification, a process that uses machine learning algorithms to categorises pixels, and explored how that can be used in remote sensing, such as for land-use mapping. I'm taking the data science module, so it was interesting to see familiar methods, including classification and regression trees, applied to challenges in remote-sensing. We looked at both supervised and unsupervised methods; supervised learning involves training a model on pre-labeled data to recognise patterns, while unsupervised methods identify clusters within the data, which are then labeled.

#### Supervised Machine Learning

We explored Classification and Regression Trees (CART) and Random Forests. CART creates a decision tree by iteratively partitioning the data based on feature values, aiming to create homogeneous groups within each partition. Random Forests builds on this by using multiple decision trees on random subsets of the data and averaging their predictions. Both methods are good at capturing complex, non-linear relationships between the spectral data and land cover classes.

Another supervised method we looked at was Support Vector Machines (SVMs). SVMs work by finding the optimal hyperplane that separates different classes in the data. They aim to maximize the margin between the hyperplane and the closest data points (support vectors). This method is particularly useful when dealing with complex spectral data, as SVMs can effectively handle the high-dimensional datasets common in satellite imagery [@maulik2017]. All of these supervised methods require labeled training data, where pixels are already associated with known land cover types, to learn the patterns and build the classification model.

**Unsupervised Machine Learning**

Unsupervised classification is employed when we lack prior knowledge about the specific land cover classes present in an image. Essentially, the algorithm is tasked with finding patterns within the data itself. It operates by grouping pixels based on their spectral similarities, without relying on any pre-labeled training data.

We looked at two different unsupervised methods; ISODATA, which iteratively refines clusters based on spectral distance, and DBSCAN, which identifies clusters based on pixel density, and effectively handles irregular shapes and noise.

**So which method to choose?**

There is no perfect algorithm that is best for every scenario. The best algorithm is case-specfic and depends on the quality and quantity of training data as well as the desired balance between model complexity and interpretability. It may also be useful to experiment with multiple classifiers to assess what fits your data the best in practice. We will look more into this next week when we learn about accuracy measures.\

## Application

A popular phenomena in remote sensing research is land use and land cover mapping [@avci2023]. Classification methods involves categorising each pixel into classes based on its spectral characteristics [@maulik2017].

Teluguntla et al., (2018) used a random forest to precisely classify cropland in Australia and China [@teluguntla2018].

existing global and regional cropland products were derived from medium to coarse resolution (250-m to 1-km) remote sensing data. They needed highly accurate 30-m cropland data as precise cropland maps are crucial for understanding and managing resources related to food and water.

the random forest (RF) model was trained using a **comprehensive and iterative approach** involving a large collection of reference data and careful consideration of various factors. To label their data - Ground data was collected in field visits. Over 628 samples were collected in Australia [@teluguntla2018].

additionally **Sub-meter to 5-m Very High Resolution Imagery (VHRI)**, available for the entire study region, was used to generate cropland versus non-cropland interpretations by multiple analysts across China and Australia, resulting in approximately 1490 data samples.

The authors selected a random forest model as they can handle high-dimensionality, and are suitable for large datasets.

To note - The authors referenced similar research that used SVM methods but they chose not too as an RF is easier to be implement.

![](images/clipboard-1512575338.png)

[@teluguntla2018; p. 338]

a more complicated classifcation case in remote sensing: Object detection - \> involves identifying the locations and types of specific targets within an image and labeling them with bounding boxes.

more complicated problems need more specialised techniques:

moving beyond basic machine learning techniques, there has been developments in deep learning methods. ANNs and CNNs -\> [@yang]

**Artificial Neural Networks (ANNs)**: use many hidden layers to model multiple levels of abstraction, have shown great promise in remote sensing, often outperforming methods like SVM for tasks like hyperspectral image classification**. Convolutional Neural Networks (CNNs)**, a type of deep learning model, are particularly good at exploiting semantic features of imagery data by directly extracting features from massive amounts of imagery. [@maxwell2018]. reword

a brand new model for specifically detecting objects in satellite imagery. [@yang] RS-YOLOX CNN

"Unlike traditional methods that rely on manual feature selection, modern deep learning-based models learn patterns directly from the data. The researchers improved previous YOLOX model by adding Efficient Channel Attention (ECA), which helps the model focus on important parts of an image while ignoring background noise. They also used Adaptively Spatial Feature Fusion (ASFF), which enhances the detection of small objects by combining information from different scales in an image. Additionally, they replaced the standard training loss function with Varifocal Loss (VFL) to better balance the learning of hard-to-detect objects." - copied from Yohan Newsletter

"Traditional detection algorithms are not effective in detecting objects in re‐mote sensing images. This is because traditional detection and the recognition of remote sensing image targets are mainly based on manually extracting features, and the rich,diverse, and detailed information in remote sensing images means that a single feature described manually is inadequate at fully expressing the target characteristics and relies more on expert experience" - page 2 [@yang]

"In addition, machine learning based on probability and statistics usually requires complex feature description, and the feature representation learned on the basis of its shallow network structure is obviously insufficient in terms of performance and generalization ability when dealing with complex target detection problems." -page 2/3

specialised solution -\> outperforms traditional models. Improves overall accuracy although more computationally intensive.

object detection in satellite remote sensing images, which is valuable for **resource exploration** and **natural disaster assessment**

[@yang]

What factors influence the selection of machine learning classifiers -\> why pick one model over the other?

<https://arxiv.org/pdf/2502.02850>

## Reflection

cool

looking into the future -\> this week out of all the others has shown how this field is rapidly adapting and changing.

in general -\> must be specific to Remote sensing - generalised machine learning models meant for images are not powerful enough.

[@rolf] paper argues that the distinctive characteristics of satellite imagery set it apart from machine learning used for images, videos, text etc., - temporal and spatial characteristics, spectral channels (multi-channel) - author says popular libraries such as TorchVision do not support more than 3-channels.

"We outline critical discussion questions and actionable suggestions to transform SatML from merely an intriguing application area to a dedicated research discipline that helps move the needle on big challenges for machine learning and society."

The author argues that current machine learning methods are not robust enough because they are tailored to other data modalities and don't address the unique characteristics and challenges of satellite data.  exemplified by custom models -\> e.g., the YOLO model adapted to detect landslides, the various technical additions to this new RS-YOLOx,

models must be trained on all the extensive and unique data availibe to satellite data -\> computer intensive to train.

**differences such as spatial and temporal scales, spectral channels, data volume, annotation sparsity, and deployment considerations.**

relate this to google earth engine - a domain specific software with built in algos

The potential of satellite data

[https://arxiv.org/abs/2402.01444](https://arxiv.org/abs/2402.01444?ref=newsletter.terrawatchspace.com){.uri}

With AI and advanced Neural networks - alot of the nuance can be lost behind these black-box algorithms explainability could be lost which is concerning.

Understanding a model's function and visualizing interpretations are critical in remote sensing applications to gain scientific insights and assess trustworthiness

<https://ieeexplore.ieee.org/abstract/document/10742949>

other Challenges for models

**Potential for overfitting**: Especially with powerful classifiers, there's a risk of the model learning the training data too precisely, hindering its ability to generalize to new data.

**Training data requirements**: The quantity and quality of training data significantly impact classifier performance. extensive field work may be required to correctly label data!

**Feature space impacts and reduction**: The choice and processing of features from the remote sensing data can greatly influence classification accuracy
