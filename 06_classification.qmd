# Classification I

## Summary

This week we learned about image classification, a process that uses machine learning algorithms to categorises pixels, and explored how that can be used in remote sensing, such as for land-use mapping. I'm taking the data science module, so it was interesting to see familiar methods, including classification and regression trees, applied to challenges in remote-sensing. We looked at both supervised and unsupervised methods; supervised learning involves training a model on pre-labeled data to recognise patterns, while unsupervised methods identify clusters within the data, which are then labeled.

#### Supervised Machine Learning

We explored Classification and Regression Trees (CART) and Random Forests. CART creates a decision tree by iteratively partitioning the data based on feature values, aiming to create homogeneous groups within each partition. Random Forests builds on this by using multiple decision trees on random subsets of the data and averaging their predictions. Both methods are good at capturing complex, non-linear relationships between the spectral data and land cover classes.

Another supervised method we looked at was Support Vector Machines (SVMs). SVMs work by finding the optimal hyperplane that separates different classes in the data. They aim to maximize the margin between the hyperplane and the closest data points (support vectors). This method is particularly useful when dealing with complex spectral data, as SVMs can effectively handle the high-dimensional datasets common in satellite imagery [@maulik2017]. All of these supervised methods require labeled training data, where pixels are already associated with known land cover types, to learn the patterns and build the classification model.

**Unsupervised Machine Learning**

Unsupervised classification is employed when we lack prior knowledge about the specific land cover classes present in an image. Essentially, the algorithm is tasked with finding patterns within the data itself. It operates by grouping pixels based on their spectral similarities, without relying on any pre-labeled training data.

We looked at two different unsupervised methods; ISODATA, which iteratively refines clusters based on spectral distance, and DBSCAN, which identifies clusters based on pixel density, and effectively handles irregular shapes and noise.

**So which method to choose?**

There is no perfect algorithm that is best for every scenario. The best algorithm is case-specfic and depends on the quality and quantity of training data as well as the desired balance between model complexity and interpretability. It may also be useful to experiment with multiple classifiers to assess what fits your data the best in practice. We will look more into this next week when we learn about accuracy measures.\

## Application

A popular phenomena in remote sensing research is land use and land cover mapping [@avci2023]. Classification methods involves categorising each pixel into classes based on its spectral characteristics [@maulik2017].

Teluguntla et al., (2018) used a random forest to precisely classify cropland in Australia and China [@teluguntla2018].

Existing global and regional cropland products were derived from medium to coarse resolution (250-m to 1-km) remote sensing data. They needed highly accurate 30-m cropland data as precise cropland maps are crucial for understanding and managing resources related to food and water.

The random forest (RF) model was trained using an iterative approach involving a large collection of reference data. To label their data - Ground data was collected in field visits. Over 628 samples were collected in Australia [@teluguntla2018]. Additionally Sub-meter to 5-m Very High Resolution Imagery (VHRI), available for the entire study region, was used to generate cropland versus non-cropland interpretations by multiple analysts across China and Australia, resulting in approximately 1490 data samples. This demonstrates how the process of 'supervising' / labeling data for machine learning can be as intense as the analysis itself.

![](images/clipboard-1512575338.png)

[@teluguntla2018; p. 338]

This intensive supervised learning approach is not uncommon, as existing pre-labelled data is sparse especially in remote sensing [@xu2023].

The quantity and quality of training data significantly impact classifier performance so extensive field work may be required to correctly label data.

## Reflection

This week highlighted remote sensing's rapid development and its technical challenges. Tools like deep learning offer transformative capabilities, but, their integration into policy faces hurdles, particularly regarding data quality, computational costs, and model transparency. For instance, extensive fieldwork for training data labelling is resource-intensive, which could complicate policy applications.

In a similar vain, in the literature, I found a debate between the need for domain-specific models and utilising repurposed computer vision libraries given computational resources required for training [@rolf; @lahrichi]. [@rolf] suggests that satellite data’s temporal, spatial, and spectral complexity, require tailored solutions rather than repurposed computer vision libraries. However, [@lahrichi] argues that the costs may outweigh the benefits. This debate emphasises balancing innovation with practicality and shows that this field is still in its infancy.

Another concern is “black-box” algorithms risk eroding trust in critical applications like disaster monitoring. Explainability must remain at the forefront of remote sensing, ensuring stakeholders understand critical model decisions.
